#
# puppet: modules/htcondor/templates/etc/condor/config.d/00masterd.conf.erb
#
# Hiera: values in hieradata/batch_ms.yaml
# 
#         (Attention: changes will be overwritten by puppet)
#
###
# Global config
###

CONDOR_HOST = htcondor_master

## Master is also submit host for test_purposes at the moment
#DAEMON_LIST = MASTER, COLLECTOR, NEGOTIATOR, GANGLIAD, SCHEDD, HAD, REPLICATION
# no replication/HA
#DAEMON_LIST = MASTER, COLLECTOR, NEGOTIATOR, GANGLIAD, SCHEDD
DAEMON_LIST = MASTER, COLLECTOR, NEGOTIATOR, SCHEDD
GANGLIA_SEND_DATA_FOR_ALL_HOSTS = true

#ALLOW_ADMINISTRATOR = $(CONDOR_HOST), $(IP_ADDRESS)
ALLOW_ADMINISTRATOR = *

DEFAULT_DOMAIN_NAME = docker-welt
UID_DOMAIN = docker-welt
FILESYSTEM_DOMAIN = $(UID_DOMAIN)
#ALLOW_WRITE = *.$(UID_DOMAIN)
#ALLOW_READ  = *.$(UID_DOMAIN)
ALLOW_WRITE = *
ALLOW_READ = *
CONDOR_ADMIN = goegrid_admin@physik.uni-goettingen.de
COLLECTOR_NAME = GoeGrid Condor Pool - $(CONDOR_HOST)

## use shared ports
USE_SHARED_PORT=False
#SHARED_PORT_ARGS = -p 9620
#COLLECTOR_USES_SHARED_PORT=FALSE
#COLLECTOR_HOST = $(CONDOR_HOST):9618
StartJobs = true

### Logging & debugging
# --> 00logging.conf
###

#NEGOTIATOR_DEBUG = D_FULLDEBUG
#SCHEDD = D_FULLDEBUG

## fill WNs horizontal not vertical as default (fill slot 1 on all nodes first, then slot 2 and so on)
NEGOTIATOR_POST_JOB_RANK = (RemoteOwner =?= UNDEFINED) * SlotID

## Resort grouplist for negotiator to prefer multicorejobs

GROUP_SORT_EXPR = ifThenElse(AccountingGroup=?="<none>", 3.4e+38,                                                                 \
                  ifThenElse(regexp("multicore",AccountingGroup),ifThenElse(GroupQuota > 0,-2+GroupResourcesInUse/GroupQuota,-1), \
                  ifThenElse(GroupQuota > 0, GroupResourcesInUse/GroupQuota, 3.3e+38)))


###
# resource limits
###

# moved to 09arc_cleanup.conf.erb ## Held jobs - don't want them to stay in the system forever - removing them after 80 hours
# moved to 09arc_cleanup.conf.erb RemoveHeldJobs = ( (JobStatus==5 && (CurrentTime - EnteredCurrentStatus) > 60 * 60 * 80) )

# moved to 09arc_cleanup.conf.erb ## Remove ALL jobs that got queued more than two weeks ago
# moved to 09arc_cleanup.conf.erb RemoveAllJobsOlderThan2Weeks = (( CurrentTime - QDate > 60 * 60 * 24 * 14))

## Try re-running held jobs once only after waiting 30 minutes
SYSTEM_PERIODIC_RELEASE = (( CurrentTime - EnteredCurrentStatus > 30 * 60) && ( JobRunCount < 2))

# moved to 09arc_cleanup.conf.erb ## Make sure jobs don't start running too many times
# moved to 09arc_cleanup.conf.erb RemoveMultipleRunJobs = ( JobRunCount > 10 )

# moved to 09arc_cleanup.conf.erb ## Time limits
# moved to 09arc_cleanup.conf.erb RemoveDefaultJobWallTime = ( RemoteWallClockTime > 80 * 60 * 60 )
# moved to 09arc_cleanup.conf.erb ##RemoveDefaultJobCpuTime  = ( RemoteSysCpu + RemoteUserCpu > 80 * 60 * 60 )

## Memory usage limit
RemoveMemoryUsage = ( ResidentSetSize_RAW > 1000*RequestMemory )

# moved to 09arc_cleanup.conf.erb ## Removal of jobs exceeding resource limits
# moved to 09arc_cleanup.conf.erb SYSTEM_PERIODIC_REMOVE = $(RemoveHeldJobs)           || \
# moved to 09arc_cleanup.conf.erb                          $(RemoveMultipleRunJobs)    || \
# moved to 09arc_cleanup.conf.erb 			 $(RemoveDefaultJobWallTime) || \
# moved to 09arc_cleanup.conf.erb 			 $(RemoveAllJobsOlderThan2Weeks)


EVENT_LOG = $(LOG)/EventLog
EVENT_LOG_JOB_AD_INFORMATION_ATTRS=Owner,CurrentHosts,x509userproxysubject,x509UserProxyVOName,AccountingGroup,GlobalJobId,QDate,JobStartDate,JobCurrentStartDate,JobFinishedHookDone

###
# /Accounting 
###

###
# QUOTAS
###
#GROUP_NAMES = group_ATLAS, group_Ops, group_Theorie,
#GROUP_QUOTA_DYNAMIC_group_ATLAS = 0.60
#GROUP_QUOTA_DYNAMIC_group_THEORIE = 0.40
#GROUP_QUOTA_DYNAMIC_group_OPS = 0.1


# AG
#GROUP_ACCEPT_SURPLUS = TRUE
#GROUP_ACCEPT_SURPLUS_ATLAS = FALSE




###
# /QUOTAS
###

###
# HA setup for condor master
###

## Define the port number on which the condor_had daemon will
## listen. The port must match the port number used
## for when defining HAD_LIST. This port number is
## arbitrary; make sure that there is no port number collision
## with other applications.
#HAD_PORT = 51450
#HAD_ARGS = -p $(HAD_PORT)
## The following macro defines the port number condor_replication will listen
## on on this machine. This port should match the port number specified
## for that replication daemon in the REPLICATION_LIST
## Port number is arbitrary (make sure no collision with other applications)
## This is a sample port number
#REPLICATION_PORT = 41450
#REPLICATION_ARGS = -p $(REPLICATION_PORT)
## The following list must contain the same addresses
## as HAD_LIST. In addition, for each hostname, it should specify
## the port number of condor_replication daemon running on that host.
## This parameter is mandatory and has no default value
#REPLICATION_LIST = \
#$(CENTRAL_MANAGER1):$(REPLICATION_PORT), \
#$(CENTRAL_MANAGER2):$(REPLICATION_PORT)
## The following list must contain the same addresses in the same order
## as CONDOR_HOST. In addition, for each hostname, it should specify
## the port number of condor_had daemon running on that host.
## The first machine in the list will be the PRIMARY central manager
## machine, in case HAD_USE_PRIMARY is set to true.
#HAD_LIST = \
#$(CENTRAL_MANAGER1):$(HAD_PORT), \
#$(CENTRAL_MANAGER2):$(HAD_PORT)
## The following is the name of the daemon that the HAD controls.
## This must match the name of a daemon in the master's DAEMON_LIST.
## The default is NEGOTIATOR, but can be any daemon that the master
## controls.
#HAD_CONTROLLEE = NEGOTIATOR
## HAD connection time.
## Recommended value is 2 if the central managers are on the same subnet.
## Recommended value is 5 if Condor security is enabled.
## Recommended value is 10 if the network is very slow, or
## to reduce the sensitivity of HA daemons to network failures.
#HAD_CONNECTION_TIMEOUT = 2
##If true, the first central manager in HAD_LIST is a primary.
#HAD_USE_PRIMARY = true

###################################################################
## THE PARAMETERS BELOW ARE ALLOWED TO BE DIFFERENT ON EACH
 #
## CENTRAL MANAGER
 #
## THESE ARE MASTER SPECIFIC PARAMETERS
###################################################################

## the master should start at least these four daemons
#DAEMON_LIST = MASTER, COLLECTOR, NEGOTIATOR, HAD, REPLICATION
## Enables/disables the replication feature of HAD daemon
## Default: false
#HAD_USE_REPLICATION = true
## Name of the file from the SPOOL directory that will be replicated
## Default: $(SPOOL)/Accountantnew.log
#STATE_FILE = $(SPOOL)/Accountantnew.log
## Period of time between two successive awakenings of the replication daemon
## Default: 300
#REPLICATION_INTERVAL = 300
## Period of time, in which transferer daemons have to accomplish the
## downloading/uploading process
## Default: 300
#MAX_TRANSFER_LIFETIME = 300
## Period of time between two successive sends of classads to the collector by HAD
## Default: 300
#HAD_UPDATE_INTERVAL = 300
## The HAD controls the negotiator, and should have a larger
## backoff constant
#MASTER_NEGOTIATOR_CONTROLLER = HAD
#MASTER_HAD_BACKOFF_CONSTANT = 360


## Testing
#ALL_DEBUG = D_ALL
ALLOW_WRITE_NEGOTIATOR = *
ALLOW_READ_NEGOTIATOR = *


